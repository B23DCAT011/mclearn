{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37b5536d-0d86-4365-a9bc-c93df348f471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "means = [[-1, -1], [1, -1], [0, 1]]\n",
    "cov = [[1, 0], [0, 1]]\n",
    "N = 20\n",
    "X0 = np.random.multivariate_normal(means[0], cov, N)\n",
    "X1 = np.random.multivariate_normal(means[1], cov, N)\n",
    "X2 = np.random.multivariate_normal(means[2], cov, N)\n",
    "X = np.concatenate((X0, X1, X2), axis=0)\n",
    "y = np.asarray([0] * N + [1] * N + [2] * N)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(50,), max_iter=10000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "acc = 100 * np.mean(y_pred == y)\n",
    "print('Training accuracy: %.2f %%' % acc)\n",
    "\n",
    "\n",
    "def softmax_stable(Z):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in Z.\n",
    "    each ROW of Z is a set of scores.\n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z - np.max(Z, axis = 1, keepdims = True))\n",
    "    A = e_Z / e_Z.sum(axis = 1, keepdims = True)\n",
    "    return A\n",
    "def crossentropy_loss(Yhat, y):\n",
    "    \"\"\"\n",
    "    Yhat: a numpy array of shape (Npoints, nClasses) -- predicted output\n",
    "    y: a numpy array of shape (Npoints) -- ground truth.\n",
    "    NOTE: We donâ€™t need to use the one-hot vector here since most of elements\n",
    "    are zeros. When programming in numpy, in each row of Yhat, we need to access\n",
    "    to the corresponding index only.\n",
    "    \"\"\"\n",
    "    id0 = range(Yhat.shape[0])\n",
    "    return -np.mean(np.log(Yhat[id0, y]))\n",
    "def mlp_init(d0, d1, d2):\n",
    "    \"\"\"\n",
    "    Initialize W1, b1, W2, b2\n",
    "    d0: dimension of input data\n",
    "    d1: number of hidden unit\n",
    "    d2: number of output unit = number of classes\n",
    "    \"\"\"\n",
    "    W1 = 0.01*np.random.randn(d0, d1)\n",
    "    b1 = np.zeros(d1)\n",
    "    W2 = 0.01*np.random.randn(d1, d2)\n",
    "    b2 = np.zeros(d2)\n",
    "    return (W1, b1, W2, b2)\n",
    "def mlp_predict(X, W1, b1, W2, b2):\n",
    "    \"\"\"\n",
    "    Suppose that the network has been trained, predict class of new points.\n",
    "    X: data matrix, each ROW is one data point.\n",
    "    W1, b1, W2, b2: learned weight matrices and biases\n",
    "    \"\"\"\n",
    "    Z1 = X.dot(W1) + b1 # shape (N, d1)\n",
    "    A1 = np.maximum(Z1, 0) # shape (N, d1)\n",
    "    Z2 = A1.dot(W2) + b2 # shape (N, d2)\n",
    "    return np.argmax(Z2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97f61e19-aee6-483a-b0dc-844ff6c583be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_fit(X, y, W1, b1, W2, b2, eta):\n",
    "    loss_hist = []\n",
    "    for i in range(20000): # number of epoches\n",
    "        # feedforward\n",
    "        Z1 = X.dot(W1) + b1 # shape (N, d1)\n",
    "        A1 = np.maximum(Z1, 0) # shape (N, d1)\n",
    "        Z2 = A1.dot(W2) + b2 # shape (N, d2)\n",
    "        Yhat = softmax_stable(Z2) # shape (N, d2)\n",
    "        if i %1000 == 0: # print loss after each 1000 iterations\n",
    "            loss = crossentropy_loss(Yhat, y)\n",
    "            print(\"iter %d, loss: %f\" %(i, loss))\n",
    "            loss_hist.append(loss)\n",
    "            \n",
    "        # back propagation\n",
    "        id0 = range(Yhat.shape[0])\n",
    "        Yhat[id0, y] -=1\n",
    "        E2 = Yhat/N # shape (N, d2)\n",
    "        dW2 = np.dot(A1.T, E2) # shape (d1, d2)\n",
    "        db2 = np.sum(E2, axis = 0) # shape (d2,)\n",
    "        E1 = np.dot(E2, W2.T) # shape (N, d1)\n",
    "        E1[Z1 <= 0] = 0 # gradient of ReLU, shape (N, d1)\n",
    "        dW1 = np.dot(X.T, E1) # shape (d0, d1)\n",
    "        db1 = np.sum(E1, axis = 0) # shape (d1,)\n",
    "        # Gradient Descent update\n",
    "        W1 += -eta*dW1\n",
    "        b1 += -eta*db1\n",
    "        W2 += -eta*dW2\n",
    "        b2 += -eta*db2\n",
    "    return (W1, b1, W2, b2, loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3eb5af-e05c-420e-933b-3510c11137e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 1.098734\n",
      "iter 1000, loss: 0.224423\n",
      "iter 2000, loss: 0.116419\n",
      "iter 3000, loss: 0.085216\n",
      "iter 4000, loss: 0.035879\n",
      "iter 5000, loss: 0.031397\n",
      "iter 6000, loss: 0.030207\n",
      "iter 7000, loss: 0.029803\n",
      "iter 8000, loss: 0.029445\n",
      "iter 9000, loss: 0.029299\n",
      "iter 10000, loss: 0.029364\n",
      "iter 11000, loss: 0.029017\n",
      "iter 12000, loss: 0.028937\n",
      "iter 13000, loss: 0.028861\n",
      "iter 14000, loss: 0.028783\n",
      "iter 15000, loss: 0.028710\n",
      "iter 16000, loss: 0.029833\n",
      "iter 17000, loss: 0.028990\n",
      "iter 18000, loss: 0.028539\n",
      "iter 19000, loss: 0.032915\n",
      "training accuracy: 98.33 %\n"
     ]
    }
   ],
   "source": [
    "# suppose X, y are training input and output, respectively\n",
    "d0 = 2 # data dimension\n",
    "d1 = h = 100 # number of hidden units\n",
    "d2 = C = 3 # number of classes\n",
    "eta = 1 # learning rate\n",
    "(W1, b1, W2, b2) = mlp_init(d0, d1, d2)\n",
    "(W1, b1, W2, b2, loss_hist) =mlp_fit(X, y, W1, b1, W2, b2, eta)\n",
    "y_pred = mlp_predict(X, W1, b1, W2, b2)\n",
    "acc = 100*np.mean(y_pred == y)\n",
    "print('training accuracy: %.2f %%' % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a7f74-479c-4d68-b744-1adce449292b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
